include: _default_template_yaml
task: mvbench_episodic_reasoning_think
dataset_name: episodic_reasoning
test_split: train
# doc_to_visual: !function utils.mvbench_frames_doc_to_visual
# generation_kwargs:
#   max_new_tokens: 16
#   temperature: 0
#   top_p: 1.0
#   num_beams: 1
#   do_sample: false
  
lmms_eval_specific_kwargs:
  default:
    sub_task: episodic_reasoning
    post_prompt: "\nPlease think about this question as if you were a human pondering deeply. Engage in an internal dialogue using expressions such as 'let me think', 'wait', 'Hmm', 'oh, I see', 'let's break it down', etc, or other natural language thought expressions. It's encouraged to include self-reflection or verification in the reasoning process. Provide your detailed reasoning between the <think> and </think> tags, and then give your final answer between the <answer> and </answer> tags."

# metadata:
#   task_type: video
#   sample_frames: 32 # for episodic reasoning, it stores the frame images in folder so we need to set the number of frames to sample here.